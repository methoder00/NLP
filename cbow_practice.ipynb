{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a47eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981dc89",
   "metadata": {},
   "source": [
    "## array of alphabet depending on adjacency > CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0b800393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. example dataset\n",
    "# Depending on how close alphabet located in keyboard\n",
    "words = [['qwe'],\n",
    "['qws'],\n",
    "['qas'],\n",
    "['qaz'],\n",
    "['wqa'],\n",
    "['wsa'],\n",
    "['wsd'],\n",
    "['wsx'],\n",
    "['wed'],\n",
    "['ewq'],\n",
    "['ews'],\n",
    "['eds'],\n",
    "['edc'],\n",
    "['aqw'],\n",
    "['asw'],\n",
    "['asd'],\n",
    "['asx'],\n",
    "['azx'],\n",
    "['swq'],\n",
    "['swe'],\n",
    "['saq'],\n",
    "['saz'],\n",
    "['sxz'],\n",
    "['sxc'],\n",
    "['sde'],\n",
    "['sdc'],\n",
    "['dew'],\n",
    "['dcx'],\n",
    "['dsa'],\n",
    "['dsw'],\n",
    "['dsx'],\n",
    "['zas'],\n",
    "['zxs'],\n",
    "['zaq'],\n",
    "['zxc'],\n",
    "['xza'],\n",
    "['xsa'],\n",
    "['xsd'],\n",
    "['xsw'],\n",
    "['xcd'],\n",
    "['cxz'],\n",
    "['cde'],\n",
    "['cxs'],\n",
    "['cds'],\n",
    "]\n",
    "df = pd.DataFrame(data=words, copy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2576c91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w', 'e', 'x', 'q', 'z', 'c', 'd', 'a', 's']\n"
     ]
    }
   ],
   "source": [
    "#2. One Hot encoder : 총 데이터 프레임내에서 중복되지 않는 알파벳 정렬 후 각각의 알파벳을 one hot encoding\n",
    "apb = []\n",
    "for i in range(len(df[0])):\n",
    "    apb.extend(df[0][i])\n",
    "b = list(set(apb))\n",
    "c = np.identity(len(b))\n",
    "# b[i]:word = c[i]:one-hot encoding\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "105ab6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. shallow embedding\n",
    "k = 3 \n",
    "#dimension of embedding\n",
    "u = np.random.rand(len(b),k)\n",
    "v = np.random.rand(k,len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "04a74606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "[0.05310138 0.59672624 0.04464656]\n"
     ]
    }
   ],
   "source": [
    "#4. Surrounding embedding\n",
    "s1 = np.matmul(v,c[b.index(df[0][0][0])])\n",
    "s2 = np.matmul(v,c[b.index(df[0][0][2])])\n",
    "print(s2.shape)\n",
    "print(s2)\n",
    "sur_emb = (s1+s2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8c701116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74538274 0.59338882 0.916213   0.91679957 0.4810518  0.91245864\n",
      " 0.84782882 1.09382932 0.71353009]\n"
     ]
    }
   ],
   "source": [
    "#5. Predict value\n",
    "pred = np.matmul(u,sur_emb)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dbc993c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10335678653668554, 0.0887828084870875, 0.1226110577895421, 0.12268299821329424, 0.07934901310678186, 0.12215159461538895, 0.11450666427078708, 0.1464425982327593, 0.10011647874767346]\n"
     ]
    }
   ],
   "source": [
    "#6. Softmax\n",
    "sm_pred = []\n",
    "sum1 = 0\n",
    "for i in range(len(pred)):\n",
    "    sum1 += np.exp(pred[i])\n",
    "for i in range(len(pred)):\n",
    "    sm_pred.append(np.exp(pred[i])/sum1)\n",
    "print(sm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a8b7f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.10335678653668554, 0.0887828084870875, 0.1226110577895421, 0.12268299821329424, 0.07934901310678186, 0.12215159461538895, 0.11450666427078708, 0.1464425982327593, 0.10011647874767346]\n",
      "2.269568329439997\n"
     ]
    }
   ],
   "source": [
    "#7. Loss function\n",
    "loss = -np.log(np.matmul(c[b.index(df[0][0][1])],sm_pred))\n",
    "print(c[b.index(df[0][0][1])])\n",
    "print(sm_pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19688bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Optimizing : Gradient Descent\n",
    "#need to study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
